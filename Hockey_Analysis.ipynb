{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-23T13:56:05.218181Z",
     "start_time": "2025-02-23T13:56:02.633854Z"
    }
   },
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import logging\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import index_definition\n",
    "import index_utils as ai\n",
    "from confidence_index import get_index_cut_by_time\n",
    "from train_online_model import predict, generate_live_match_data\n",
    "import warnings\n",
    "import common\n",
    "import dill\n",
    "import confidence_index as ci\n",
    "import feature_utils\n",
    "# 忽略所有警告\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,  \n",
    "#     format='%(asctime)s [简记] %(message)s',  # 去除非必要字段\n",
    "#     handlers=[\n",
    "#         logging.StreamHandler(), \n",
    "#         logging.FileHandler('data_analysis.log') \n",
    "#     ]\n",
    "# )\n",
    "\n",
    "data = pd.read_csv(\"Linhac24-25_Sportlogiq.csv\")\n",
    "data['inopponentarea'] = data.apply(common.puck_location, axis=1)\n",
    "gameids = data['gameid'].unique()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " #探究信心指数对比赛结果的影响\n",
    "# gameids = gameids[0:4]\n",
    "# team_feature_df = get_index_cut_by_time(data, gameids, index_definition.CONFIDENCE_INDEX, 120, tfrom=0, to=3600)\n",
    "# max_cols = 2  #每行最多显示2张\n",
    "# num_plots = len(gameids) * 2\n",
    "# rows = (num_plots + max_cols - 1) // max_cols\n",
    "# cols = min(max_cols, num_plots)\n",
    "# plt.figure(figsize=(15, rows * 3))\n",
    "# sns.set_theme(style=\"dark\")\n",
    "# \n",
    "# for i in range(len(gameids)):\n",
    "#     gameid = gameids[i]\n",
    "#     j = i * 2 if i > 0 else 0\n",
    "#     winner = common.get_winner(data, gameid)\n",
    "#     winnerid = winner[0]\n",
    "#     loserid = winner[1]\n",
    "#     winner_df = team_feature_df[(team_feature_df['gameid'] == gameid) & (team_feature_df['teamid'] == winnerid)]\n",
    "#     winner_goal = winner_df[winner_df['goal'] == 1]['elapsed_sec'].values\n",
    "#     loser_df = team_feature_df[(team_feature_df['gameid'] == gameid) & (team_feature_df['teamid'] == loserid)]\n",
    "#     loser_goal = loser_df[loser_df['goal'] == 1]['elapsed_sec'].values\n",
    "#     feature_names = ['accuracy_reception_succ', 'accuracy_pass_succ', 'efficient_block_succ', 'body_check']\n",
    "#     colors = sns.color_palette(\"bright\", n_colors=len(feature_names))\n",
    "#     ax = plt.subplot(rows, cols, j + 1)\n",
    "#     ax0 = plt.subplot(rows, cols, j + 2)\n",
    "#     for c, (f, color) in enumerate(zip(feature_names, colors)):\n",
    "#         sns.lineplot( x=list(winner_df['elapsed_sec']),y=list(winner_df[f]), color=color, label=f, ax=ax)\n",
    "#         ax.set_title('Game:' + str(gameid) + 'WinnerTeamid:' + str(winnerid))\n",
    "#         # sns.lineplot( x=list(loser_df['elapsed_sec']), y=list(loser_df[f]),color=color, label=f, ax=ax0)\n",
    "#         # ax0.set_title('Game:' + str(gameid) + 'LoseTeamid:' + str(loserid))\n",
    "#         for goal_time in winner_goal:\n",
    "#             ax.vlines(x=goal_time, ymin=0, ymax=ax.get_ylim()[1], color='green', linestyles='-')\n",
    "#         # for goal_time in loser_goal:\n",
    "#         #     ax0.vlines(x=goal_time, ymin=0, ymax=ax0.get_ylim()[1], color='green', linestyles='-')\n",
    "#     for c, (f, color) in enumerate(zip(feature_names, colors)):\n",
    "#         # sns.lineplot( x=list(winner_df['elapsed_sec']),y=list(winner_df[f]), color=color, label=f, ax=ax)\n",
    "#         # ax.set_title('Game:' + str(gameid) + 'WinnerTeamid:' + str(winnerid))\n",
    "#         sns.lineplot( x=list(loser_df['elapsed_sec']), y=list(loser_df[f]),color=color, label=f, ax=ax0)\n",
    "#         ax0.set_title('Game:' + str(gameid) + 'LoseTeamid:' + str(loserid))\n",
    "#         # for goal_time in winner_goal:\n",
    "#         #     ax.vlines(x=goal_time, ymin=0, ymax=ax.get_ylim()[1], color='green', linestyles='-')\n",
    "#         for goal_time in loser_goal:\n",
    "#             ax0.vlines(x=goal_time, ymin=0, ymax=ax0.get_ylim()[1], color='green', linestyles='-')\n",
    "# plt.tight_layout()\n",
    "# plt.legend()\n",
    "# plt.show()"
   ],
   "id": "4da0b128fc20a60f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## 研究第一节比赛数据是否能预测最后的比赛结果\n",
    "\n",
    "#所有比赛的整体数据分析\n",
    "events = {**index_definition.CONTEST,**index_definition.GOAL, **index_definition.PASS, **index_definition.SHOT, **index_definition.BLOCK,**index_definition.CHECK, }\n",
    "max_cols = 2  #每行最多显示2张\n",
    "num_plots = len(events) \n",
    "rows = (num_plots + max_cols - 1) // max_cols\n",
    "cols = min(max_cols, num_plots)\n",
    "plt.figure(figsize=(15, rows * 3))\n",
    "normal_time_df = data[(data['compiledgametime'] <= 3600)]\n",
    "for index, (event_name, event) in enumerate(events.items()):\n",
    "    ax = plt.subplot(rows, cols, index+1)\n",
    "    condition = normal_time_df.eval(event)\n",
    "    event_df = normal_time_df[condition]\n",
    "    bin_inter = 180\n",
    "    bins = list(np.arange(0, 3600, bin_inter))\n",
    "    bins.append(3600)\n",
    "    labels = bins[0:20]\n",
    "    event_df['cut'] = pd.cut(event_df['compiledgametime'], bins=bins, labels=labels)\n",
    "    sns.countplot(x='cut', hue='eventname', data=event_df,ax=ax)\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.set_title(event_name)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel(event_name + ' Number')\n",
    "    ax.legend(title=event_name)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# 显示图表\n",
    "plt.show()"
   ],
   "id": "273885c675a754ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#比赛0到540秒,即前9分钟,相比较与其他时间段进球的队伍，首先进球队伍的胜率非常低，只有48%，输掉比赛的概率有41%，\n",
    "# 其他时间段内普遍在60%以上，其中在后半场开场后一段时间内，进球队伍胜率最高，达到了70%以上\n",
    "start_time = 0\n",
    "end_time =  600\n",
    "total_games = 0\n",
    "first_goal_win_teams = 0\n",
    "first_goal_home_win_teams = 0\n",
    "first_goal_win_tie_teams =0\n",
    "first_goal_lost_teams = 0\n",
    "special_time_df =  data[(data['compiledgametime'] <= end_time) & (data['compiledgametime'] >= start_time) & (data['eventname'] == 'goal')]\n",
    "grouped = special_time_df.groupby('gameid')\n",
    "for gameid, gamedata in grouped:\n",
    "    total_games += 1\n",
    "    winner = common.get_winner(data, gameid)\n",
    "    home_team_id = common.get_home_team_id(data, gameid)\n",
    "    goal_team = gamedata['teaminpossession'].unique()\n",
    "    #如果这个时间段两个队伍都进球了，只计算第一个进球的队伍\n",
    "    if len(goal_team) == 2:\n",
    "        goal_team = gamedata.iloc[0]['teaminpossession']\n",
    "    else:\n",
    "        goal_team =gamedata['teaminpossession'].unique()[0]\n",
    "    if goal_team == winner[0]: #至少比赛是平局\n",
    "        first_goal_win_tie_teams += 1\n",
    "        if  winner[2] is True: #比赛不是平局\n",
    "            first_goal_win_teams += 1\n",
    "            if winner[0] == home_team_id:\n",
    "                first_goal_home_win_teams += 1\n",
    "    else:\n",
    "        first_goal_lost_teams += 1\n",
    "print('总比赛场次:', total_games,',至少平局场次:', first_goal_win_tie_teams, ',赢下比赛场次:', first_goal_win_teams, '输掉比赛场次:', first_goal_lost_teams)\n",
    "print('至少平局的概率:', first_goal_win_tie_teams / total_games)\n",
    "print('赢下比赛的概率:', first_goal_win_teams / total_games)\n",
    "print('是主队且赢下比赛的概率:', first_goal_home_win_teams / total_games)\n",
    "print('输掉比赛的概率:', first_goal_lost_teams / total_games)\n"
   ],
   "id": "3a8853c22559b883",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#探究控所有比赛主队和客队的球率\n",
    "#发现主队在开场9分钟内控球率最高，客队在开场9分钟内控球率最低，结合上面的分析，可以看出主队在开场9分钟内控球率高，如果进球,赢球的概率却最低.\n",
    "\n"
   ],
   "id": "b6fe1000b6e58d71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "##探究控所有比赛主队和客队的球率\n",
    "#发现主队在开场9分钟内控球率最高，客队在开场9分钟内控球率最低，结合上面的分析，可以看出主队在开场9分钟内控球率高，如果进球,赢球的概率却最低.\n",
    "bin_inter = 90\n",
    "plt.figure(figsize=(10, 3))\n",
    "bin_number = int(3600 / bin_inter)\n",
    "unique_gameids = data['gameid'].unique()\n",
    "gameids = unique_gameids[0:156]\n",
    "home_total_control_times = [0] * bin_number\n",
    "visit_total_control_times = [0] * bin_number\n",
    "home_total_control_rates = [0] * bin_number\n",
    "visit_total_control_rates = [0] * bin_number\n",
    "game_first_period_control_rate= {}\n",
    "game_all_period_control_times= {}\n",
    "#按队伍计算每个时间段的控球率\n",
    "game_total_control_rates = {}\n",
    "for gameid in gameids:\n",
    "    gamedata = data[(data['gameid'] == gameid)]\n",
    "    game_home_total_control_times = [0] * bin_number\n",
    "    game_visit_total_control_times = [0] * bin_number\n",
    "    bins = list(np.arange(0, 3600, bin_inter))\n",
    "    bins.append(3600)\n",
    "    for i in range(len(bins)):\n",
    "        if i + 1 == len(bins):\n",
    "            game_first_period_control_rate[gameid] = game_home_total_control_times[0] / (\n",
    "                        game_home_total_control_times[0] + game_visit_total_control_times[0])\n",
    "            game_total_control_rates[gameid] = sum(game_home_total_control_times) / (\n",
    "                        sum(game_home_total_control_times) + sum(game_visit_total_control_times))\n",
    "            game_all_period_control_times[gameid]= [game_home_total_control_times, game_visit_total_control_times]\n",
    "            break\n",
    "        tfrom = bins[i]\n",
    "        to = bins[i + 1]\n",
    "        home_control_rate, visit_control_rate, home_possession_time, visit_possession_time = common.get_control_rate0(\n",
    "            data, gameid, tfrom, to)\n",
    "        home_total_control_times[i] = sum(home_possession_time) + home_total_control_times[i]\n",
    "        visit_total_control_times[i] = sum(visit_possession_time) + visit_total_control_times[i]\n",
    "        home_total_control_rates[i] = home_total_control_times[i] / (\n",
    "                    home_total_control_times[i] + visit_total_control_times[i])\n",
    "        visit_total_control_rates[i] = visit_total_control_times[i] / (\n",
    "                    home_total_control_times[i] + visit_total_control_times[i])\n",
    "        game_home_total_control_times[i] = sum(home_possession_time) \n",
    "        game_visit_total_control_times[i] = sum(visit_possession_time) \n",
    "plt.title('Home team puck control rate')\n",
    "sns.lineplot(x=bins[1:], y=home_total_control_rates, color='r', label='Home Team')\n",
    "sns.lineplot(x=bins[1:], y=visit_total_control_rates, color='b', label='Visit Team')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "a65adf1a92c28acc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 控球率与比赛结果的关系，按时间和比赛计算\n",
    "\n",
    "max_cols = 2  #每行最多显示2张\n",
    "num_plots = 20\n",
    "rows = (num_plots + max_cols - 1) // max_cols\n",
    "cols = min(max_cols, num_plots)\n",
    "plt.figure(figsize=(15, rows * 3))\n",
    "sns.set_theme(style=\"dark\")\n",
    "for index, (gameid, game_control_times) in enumerate(game_all_period_control_times.items()):\n",
    "    if index == num_plots - 1 : break\n",
    "    home_control_times = game_control_times[0]\n",
    "    visit_control_times = game_control_times[1]\n",
    "    winner = common.get_winner(data, gameid)\n",
    "    home_team_id = common.get_home_team_id(data,gameid)\n",
    "    winnerid = winner[0]\n",
    "    loserid = winner[1]\n",
    "    ax = plt.subplot(rows, cols, index + 1)\n",
    "    sns.lineplot(x=bins[1:], y=home_control_times, color='r', label='Home Team', ax=ax)\n",
    "    title = 'Game:' + str(gameid) + ',Winner=Home Team'  if winnerid == home_team_id else 'Game:' + str(gameid) + ',Winner=Visit Team'\n",
    "    if winner[2] is False:\n",
    "        ax.set_title('Game:' + str(gameid) + ',Winner=Home Team(Tie)')\n",
    "    else:\n",
    "        ax.set_title(title)\n",
    "    # ax0 = plt.subplot(rows, cols, index * 2 + 2)\n",
    "    sns.lineplot(x=bins[1:], y=visit_control_times, color='b', label='Visit Team', ax=ax)\n",
    "    # ax.set_title('Game:' + str(gameid) + 'LoseTeamid:' + str(loserid))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "# 显示图表\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "fe92a51de4ed903a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "#所以，我们有个猜想，第一节耗能最多的球队，反而最后会输掉比赛\n",
    "#耗能的event数量太多，不一一分析，这里只分析一个event，即body_check\n",
    "#检查第一节Body check和胜率的关系\n",
    "grouped = data.groupby('gameid')\n",
    "gameids = unique_gameids.tolist()\n",
    "detail_df = ci.get_index_cut_by_time(data, gameids, {**index_definition.BODY, **index_definition.CONTEST},\n",
    "                                    time_interval=180)\n",
    "#计算前9分钟body的次数，以及比赛的结果\n",
    "detail_df = detail_df[(detail_df['elapsed_sec'] <= 1200) & (detail_df['elapsed_sec'] >= 540)]\n",
    "game_check_dict = {}\n",
    "more_body_win = 0\n",
    "less_body_win = 0\n",
    "tie = 0\n",
    "other = 0\n",
    "for gameid in gameids:\n",
    "    game_df = detail_df[detail_df['gameid'] == gameid]\n",
    "    team_ids = game_df['teamid'].unique().tolist()\n",
    "    game_check_dict[gameid] = {}\n",
    "    for teamid in team_ids:\n",
    "        team_df = game_df[game_df['teamid'] == teamid]\n",
    "        body_event_sum = team_df['contest'].sum()\n",
    "        game_check_dict[gameid][teamid] = body_event_sum\n",
    "\n",
    "for gameid, value in game_check_dict.items():\n",
    "    winner = common.get_winner(data, gameid)\n",
    "    home_team_id = common.get_home_team_id(data, gameid)\n",
    "    teamids = list(value.keys())\n",
    "    body_sums = list(value.values())\n",
    "    if body_sums[0] > body_sums[1]:\n",
    "        if winner[0] == teamids[0] and winner[2] is True:\n",
    "            more_body_win += 1\n",
    "        elif winner[0] == teamids[1] and winner[2] is True:\n",
    "            less_body_win += 1\n",
    "        elif winner[2] is False:\n",
    "            tie += 1\n",
    "    elif body_sums[0] < body_sums[1]:\n",
    "        if winner[0] == teamids[0] and winner[2] is True:\n",
    "            less_body_win += 1\n",
    "        elif winner[0] == teamids[1] and winner[2] is True:\n",
    "            more_body_win += 1\n",
    "        elif winner[2] is False:\n",
    "            tie += 1\n",
    "print(\"其他情况数量:\" + str(other))\n",
    "print(\"平局数量:\" + str(tie))\n",
    "print(\"第一节更少的body check的队伍赢得比赛数量:\" + str(less_body_win))\n",
    "print(\"第一节更多的body check的队伍赢得比赛数量:\" + str(more_body_win))\n",
    "print(\"第一节更少的body check的队伍赢得比赛的概率是：\" + str(less_body_win / len(gameids)))\n",
    "print(\"第一节更多的body check的队伍赢得比赛的概率是：\" + str(more_body_win / len(gameids)))\n",
    "\n"
   ],
   "id": "7e9e34777e078967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"Linhac24-25_Sportlogiq.csv\")\n",
    "data['inopponentarea'] = data.apply(common.puck_location, axis=1)\n",
    "unique_gameids = data['gameid'].unique()\n",
    "gameids = unique_gameids.tolist()[1:3]"
   ],
   "id": "a6cf54a4ea9b5157",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T14:07:55.763109Z",
     "start_time": "2025-02-23T14:07:41.642725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#整理数据，提取特征\n",
    "#包括两大类，一类是会影响体力的要素，一类是会影响信心指数的要素，两者也有重合的部分，比如成功的扑救会提高信心，但是会降低守门员的体力\n",
    "#这里我暂时把SAVE这个动作放入影响体力要素里面\n",
    "\n",
    "all_events_index = {**index_definition.EXERTION_INDEX, **index_definition.CONFIDENCE_INDEX}\n",
    "#将第一节时间也分成两个部分,一个是0到540秒，一个是540到1200秒\n",
    "\n",
    "first_period_index_df1 =ci.get_index_cut_by_time(data, gameids, all_events_index, 180,tfrom = 0, to = 540)\n",
    "first_period_index_df2 =ci.get_index_cut_by_time(data, gameids, all_events_index, 180,tfrom = 540, to = 1200)\n",
    "first_period_index_df3 =ci.get_index_cut_by_time(data, gameids, all_events_index, 180,tfrom = 1200, to = 1800)\n",
    "first_period_index_df4 =ci.get_index_cut_by_time(data, gameids, all_events_index, 180,tfrom = 1800, to = 2400)\n",
    "\n",
    "\n",
    "\n",
    "res1 = feature_utils.extract_relative_feature(data,first_period_index_df1,\"_p1\", all_events_index, 0, 540)\n",
    "res2 = feature_utils.extract_features(data,first_period_index_df2, \"_p2\",all_events_index, 540, 1200)\n",
    "\n",
    "res3 = feature_utils.extract_features(data,first_period_index_df3,\"_p3\", all_events_index, 1200, 1800)\n",
    "res4 = feature_utils.extract_features(data , first_period_index_df4,\"_p4\", all_events_index, 1800, 2400)\n",
    "\n",
    "res1.drop(columns=['win_p1'],inplace=True)\n",
    "merge_res = res1.merge(res2, on= ['gameid','teamid','is_home'], how='left')\n",
    "merge_res.rename(columns={'win_p2':'win'},inplace=True)\n",
    "merge_res.drop(columns =['gameid','teamid'],inplace=True)\n",
    "\n",
    "\n",
    "res3.drop(columns=['win_p3'],inplace=True)\n",
    "merge_res1 = res3.merge(res4, on= ['gameid','teamid','is_home'], how='left')\n",
    "merge_res1.rename(columns={'win_p4':'win'},inplace=True)\n",
    "merge_res1.drop(columns =['gameid','teamid'],inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "ece11f822313f998",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀 Processing:  51%|\u001B[34m█████     \u001B[0m| 79/156 [00:13<00:13,  5.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m all_events_index \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mindex_definition\u001B[38;5;241m.\u001B[39mEXERTION_INDEX, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mindex_definition\u001B[38;5;241m.\u001B[39mCONFIDENCE_INDEX}\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#将第一节时间也分成两个部分,一个是0到540秒，一个是540到1200秒\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m first_period_index_df1 \u001B[38;5;241m=\u001B[39mci\u001B[38;5;241m.\u001B[39mget_index_cut_by_time(data, gameids, all_events_index, \u001B[38;5;241m180\u001B[39m,tfrom \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m, to \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m540\u001B[39m)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m#first_period_index_df2 =ci.get_index_cut_by_time(data, gameids, all_events_index, 180,tfrom = 540, to = 1200)\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# first_period_index_df3 =ci.get_index_cut_by_time(data, gameids, all_events_index, 180,tfrom = 1200, to = 1800)\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# first_period_index_df4 =ci.get_index_cut_by_time(data, gameids, all_events_index, 180,tfrom = 1800, to = 2400)\u001B[39;00m\n\u001B[1;32m     15\u001B[0m res1 \u001B[38;5;241m=\u001B[39m feature_utils\u001B[38;5;241m.\u001B[39mextract_relative_feature(data,first_period_index_df1,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_p1\u001B[39m\u001B[38;5;124m\"\u001B[39m, all_events_index, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m540\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/Hockey/confidence_index.py:51\u001B[0m, in \u001B[0;36mget_index_cut_by_time\u001B[0;34m(df, gameids, events, time_interval, tfrom, to)\u001B[0m\n\u001B[1;32m     49\u001B[0m from_bin \u001B[38;5;241m=\u001B[39m num_bins[i]\n\u001B[1;32m     50\u001B[0m to_bin \u001B[38;5;241m=\u001B[39m num_bins[i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m---> 51\u001B[0m aindex, sindex, detail_df \u001B[38;5;241m=\u001B[39m ai\u001B[38;5;241m.\u001B[39mget_index(team_df, gameid, teamid, events, from_bin, to_bin)\n\u001B[1;32m     52\u001B[0m current_sum_confidence \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m aindex\n\u001B[1;32m     53\u001B[0m current_succ_confidence \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m sindex\n",
      "File \u001B[0;32m~/PycharmProjects/Hockey/index_utils.py:25\u001B[0m, in \u001B[0;36mget_index\u001B[0;34m(df, gameid, teamid, events, tfrom, to)\u001B[0m\n\u001B[1;32m     22\u001B[0m single_index_dict \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mteamid\u001B[39m\u001B[38;5;124m\"\u001B[39m:teamid,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgameid\u001B[39m\u001B[38;5;124m\"\u001B[39m:gameid,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melapsed_sec\u001B[39m\u001B[38;5;124m\"\u001B[39m:to,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore_diff\u001B[39m\u001B[38;5;124m\"\u001B[39m:score_diff}\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name,action \u001B[38;5;129;01min\u001B[39;00m events\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;66;03m#logging.info(f\"the number of {action} ）\")\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m     condition \u001B[38;5;241m=\u001B[39m df_copy\u001B[38;5;241m.\u001B[39meval(action)\n\u001B[1;32m     26\u001B[0m     result \u001B[38;5;241m=\u001B[39m df_copy[condition]\n\u001B[1;32m     27\u001B[0m     success_result \u001B[38;5;241m=\u001B[39m result[result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutcome\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msuccessful\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pylecture/lib/python3.11/site-packages/pandas/core/frame.py:4943\u001B[0m, in \u001B[0;36mDataFrame.eval\u001B[0;34m(self, expr, inplace, **kwargs)\u001B[0m\n\u001B[1;32m   4941\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlevel\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlevel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   4942\u001B[0m index_resolvers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_index_resolvers()\n\u001B[0;32m-> 4943\u001B[0m column_resolvers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_cleaned_column_resolvers()\n\u001B[1;32m   4944\u001B[0m resolvers \u001B[38;5;241m=\u001B[39m column_resolvers, index_resolvers\n\u001B[1;32m   4945\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pylecture/lib/python3.11/site-packages/pandas/core/generic.py:659\u001B[0m, in \u001B[0;36mNDFrame._get_cleaned_column_resolvers\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCSeries):\n\u001B[1;32m    657\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {clean_column_name(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname): \u001B[38;5;28mself\u001B[39m}\n\u001B[0;32m--> 659\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m    660\u001B[0m     clean_column_name(k): Series(\n\u001B[1;32m    661\u001B[0m         v, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, name\u001B[38;5;241m=\u001B[39mk, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtypes[k]\n\u001B[1;32m    662\u001B[0m     )\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    663\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter_column_arrays())\n\u001B[1;32m    664\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(k, \u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m    665\u001B[0m }\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pylecture/lib/python3.11/site-packages/pandas/core/generic.py:660\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCSeries):\n\u001B[1;32m    657\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {clean_column_name(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname): \u001B[38;5;28mself\u001B[39m}\n\u001B[1;32m    659\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m--> 660\u001B[0m     clean_column_name(k): Series(\n\u001B[1;32m    661\u001B[0m         v, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, name\u001B[38;5;241m=\u001B[39mk, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtypes[k]\n\u001B[1;32m    662\u001B[0m     )\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    663\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter_column_arrays())\n\u001B[1;32m    664\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(k, \u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m    665\u001B[0m }\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pylecture/lib/python3.11/site-packages/pandas/core/series.py:593\u001B[0m, in \u001B[0;36mSeries.__init__\u001B[0;34m(self, data, index, dtype, name, copy, fastpath)\u001B[0m\n\u001B[1;32m    590\u001B[0m         data \u001B[38;5;241m=\u001B[39m SingleArrayManager\u001B[38;5;241m.\u001B[39mfrom_array(data, index)\n\u001B[1;32m    592\u001B[0m NDFrame\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, data)\n\u001B[0;32m--> 593\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m=\u001B[39m name\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_axis(\u001B[38;5;241m0\u001B[39m, index)\n\u001B[1;32m    596\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m original_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m is_pandas_object \u001B[38;5;129;01mand\u001B[39;00m data_dtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mobject_:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pylecture/lib/python3.11/site-packages/pandas/core/generic.py:6320\u001B[0m, in \u001B[0;36mNDFrame.__setattr__\u001B[0;34m(self, name, value)\u001B[0m\n\u001B[1;32m   6317\u001B[0m \u001B[38;5;66;03m# if this fails, go on to more involved attribute setting\u001B[39;00m\n\u001B[1;32m   6318\u001B[0m \u001B[38;5;66;03m# (note that this matches __getattr__, above).\u001B[39;00m\n\u001B[1;32m   6319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_names_set:\n\u001B[0;32m-> 6320\u001B[0m     \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, value)\n\u001B[1;32m   6321\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata:\n\u001B[1;32m   6322\u001B[0m     \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, value)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pylecture/lib/python3.11/site-packages/pandas/core/series.py:786\u001B[0m, in \u001B[0;36mSeries.name\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m    784\u001B[0m \u001B[38;5;129m@name\u001B[39m\u001B[38;5;241m.\u001B[39msetter\n\u001B[1;32m    785\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mname\u001B[39m(\u001B[38;5;28mself\u001B[39m, value: Hashable) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 786\u001B[0m     validate_all_hashable(value, error_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.name\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_name\u001B[39m\u001B[38;5;124m\"\u001B[39m, value)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pylecture/lib/python3.11/site-packages/pandas/core/dtypes/common.py:1590\u001B[0m, in \u001B[0;36mvalidate_all_hashable\u001B[0;34m(error_name, *args)\u001B[0m\n\u001B[1;32m   1571\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidate_all_hashable\u001B[39m(\u001B[38;5;241m*\u001B[39margs, error_name: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1572\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1573\u001B[0m \u001B[38;5;124;03m    Return None if all args are hashable, else raise a TypeError.\u001B[39;00m\n\u001B[1;32m   1574\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1588\u001B[0m \u001B[38;5;124;03m    None\u001B[39;00m\n\u001B[1;32m   1589\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1590\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(is_hashable(arg) \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args):\n\u001B[1;32m   1591\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m error_name:\n\u001B[1;32m   1592\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be a hashable type\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pylecture/lib/python3.11/site-packages/pandas/core/dtypes/common.py:1590\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1571\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidate_all_hashable\u001B[39m(\u001B[38;5;241m*\u001B[39margs, error_name: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1572\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1573\u001B[0m \u001B[38;5;124;03m    Return None if all args are hashable, else raise a TypeError.\u001B[39;00m\n\u001B[1;32m   1574\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1588\u001B[0m \u001B[38;5;124;03m    None\u001B[39;00m\n\u001B[1;32m   1589\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1590\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(is_hashable(arg) \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args):\n\u001B[1;32m   1591\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m error_name:\n\u001B[1;32m   1592\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be a hashable type\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/pylecture/lib/python3.11/site-packages/pandas/core/dtypes/common.py:1590\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1571\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidate_all_hashable\u001B[39m(\u001B[38;5;241m*\u001B[39margs, error_name: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1572\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1573\u001B[0m \u001B[38;5;124;03m    Return None if all args are hashable, else raise a TypeError.\u001B[39;00m\n\u001B[1;32m   1574\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1588\u001B[0m \u001B[38;5;124;03m    None\u001B[39;00m\n\u001B[1;32m   1589\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1590\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(is_hashable(arg) \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args):\n\u001B[1;32m   1591\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m error_name:\n\u001B[1;32m   1592\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be a hashable type\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:764\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Desktop/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py:92\u001B[0m, in \u001B[0;36mcan_not_skip\u001B[0;34m(plugin, pydb, frame, info)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcan_not_skip\u001B[39m(plugin, pydb, frame, info):\n\u001B[1;32m     91\u001B[0m     step_cmd \u001B[38;5;241m=\u001B[39m info\u001B[38;5;241m.\u001B[39mpydev_step_cmd\n\u001B[0;32m---> 92\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m step_cmd \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m108\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m _is_equals(frame, _get_stop_frame(info)):\n\u001B[1;32m     93\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m pydb\u001B[38;5;241m.\u001B[39mjupyter_breakpoints:\n",
      "File \u001B[0;32m~/Desktop/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py:122\u001B[0m, in \u001B[0;36m_is_equals\u001B[0;34m(frame, other_frame)\u001B[0m\n\u001B[1;32m    118\u001B[0m             plugin_stop \u001B[38;5;241m=\u001B[39m stop_info[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjupyter_stop\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m stop, plugin_stop\n\u001B[0;32m--> 122\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_is_equals\u001B[39m(frame, other_frame):\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;66;03m# We can't compare frames directly, because Jupyter compiles ast nodes\u001B[39;00m\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;66;03m# in cell separately. At the same time, the frame filename is unique and stays\u001B[39;00m\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;66;03m# the same within a cell.\u001B[39;00m\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m frame\u001B[38;5;241m.\u001B[39mf_code\u001B[38;5;241m.\u001B[39mco_filename \u001B[38;5;241m==\u001B[39m other_frame\u001B[38;5;241m.\u001B[39mf_code\u001B[38;5;241m.\u001B[39mco_filename \\\n\u001B[1;32m    127\u001B[0m            \u001B[38;5;129;01mand\u001B[39;00m ((frame\u001B[38;5;241m.\u001B[39mf_code\u001B[38;5;241m.\u001B[39mco_name\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<cell line:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    128\u001B[0m                  \u001B[38;5;129;01mand\u001B[39;00m other_frame\u001B[38;5;241m.\u001B[39mf_code\u001B[38;5;241m.\u001B[39mco_name\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<cell line:\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m    129\u001B[0m                 \u001B[38;5;129;01mor\u001B[39;00m frame\u001B[38;5;241m.\u001B[39mf_code\u001B[38;5;241m.\u001B[39mco_name \u001B[38;5;241m==\u001B[39m other_frame\u001B[38;5;241m.\u001B[39mf_code\u001B[38;5;241m.\u001B[39mco_name)\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_stop_frame\u001B[39m(info):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#使用多种机器学习模型进行训练\n",
    "#首先使用lasso进行特征选择\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from boruta import BorutaPy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "# X = merge_res.iloc[:,:-1]\n",
    "# y = merge_res['win']\n",
    "\n",
    "X = merge_res1.iloc[:,:-1]\n",
    "y = merge_res1['win']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. 训练 Lasso 回归模型\n",
    "#lasso = LogisticRegression(penalty='l1', solver='liblinear', multi_class='ovr', C=0.1)\n",
    "lasso = LogisticRegression(\n",
    "    penalty='l1',        # L1正则化(Lasso)\n",
    "    solver='liblinear',  # 专门优化二分类问题的求解器\n",
    "    C=0.1,               # 正则化强度（更小值=更强正则化）\n",
    "    random_state=42\n",
    ")\n",
    "lasso.fit(X_scaled, y_train)\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "\n",
    "# 4. 获取特征重要性（Lasso 回归的系数）\n",
    "# 获取 Lasso 的特征系数\n",
    "feature_importance = np.abs(lasso.coef_).sum(axis=0)  # 对 OvR 分类器求和\n",
    "feature_names = X.columns  # 获取特征名称\n",
    "\n",
    "# 按重要性排序\n",
    "sorted_idx = np.argsort(feature_importance)[::-1] \n",
    "sorted_features = np.array(feature_names)[sorted_idx]\n",
    "sorted_importance = feature_importance[sorted_idx]\n",
    "# sorted_indices = np.argsort(feature_importance)[::-1]  # 按重要性降序排序\n",
    "# sorted_features = X.columns[sorted_indices]\n",
    "# sorted_importance = feature_importance[sorted_indices]\n",
    "\n",
    "\n",
    "# 5. 可视化特征重要性\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.barh(range(len(sorted_importance)), sorted_importance, tick_label=sorted_features, color='royalblue')\n",
    "plt.xlabel(\"Importance (Lasso Coefficients)\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Feature\", fontsize=12)\n",
    "plt.title(\"Feature Importance using Lasso Regression\", fontsize=14)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)  # 缩小特征名称字体\n",
    "plt.gca().invert_yaxis()  # 让重要特征排在上面\n",
    "plt.show()\n",
    "\n",
    "# 6. 打印最重要的特征\n",
    "# important_features = np.where(feature_importance > 0)[0]\n",
    "# print(f\"重要特征索引: {sorted_importance}\")\n",
    "# print(f\"对应的 Lasso 重要性系数: {lasso.coef_[sorted_importance]}\")\n",
    "# 计算准确率 & F1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 输出评估指标\n",
    "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
    "print(f\"⚡ F1-Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "conf_matrix = confusion_matrix(y_test.astype(int), y_pred.astype(int))\n",
    "labels = np.unique(y_test)  # 确保只显示真实存在的类别\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "8ac6f45087600c8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model = xgb.XGBClassifier(objective=\"multi:softmax\",nclass=2,n_estimators=100, random_state=42,\n",
    "#                           eval_metric=\"mlogloss\", use_label_encoder=False)\n",
    "\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",  # 二分类任务\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\"  # 适用于二分类\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)  # 计算 AUC 用\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "#auc = roc_auc_score(y_test, y_prob,multi_class=\"ovr\")\n",
    "auc = roc_auc_score(y_test, y_prob[:, 1])\n",
    "\n",
    "f1 = f1_score(y_test, y_pred,average=\"weighted\")\n",
    "\n",
    "print(f\"✅ 模型评估结果:\")\n",
    "print(f\"🎯 Accuracy: {acc:.4f}\")\n",
    "print(f\"📈 AUC: {auc:.4f}\")\n",
    "print(f\"⚡ F1-Score: {f1:.4f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "labels = np.unique(y_test)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "importance = model.feature_importances_\n",
    "\n",
    "sorted_indices = np.argsort(importance)[::-1]  # 按重要性降序排序\n",
    "sorted_features = X.columns[sorted_indices]\n",
    "sorted_importance = importance[sorted_indices]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.barh(sorted_features, sorted_importance, color=\"royalblue\")\n",
    "plt.xlabel(\"Feature Importance Score\", fontsize=12)\n",
    "plt.ylabel(\"Feature\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Feature Importance using XGBoost\", fontsize=14)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.gca().invert_yaxis()  # 让重要特征排在上方\n",
    "plt.show()\n"
   ],
   "id": "f52cc2fa356acd66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Boruta算法筛选因子\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "# rf = RandomForestRegressor(n_jobs=-1, n_estimators=100, random_state=42)\n",
    "\n",
    "\n",
    "boruta_selector = BorutaPy(xgb_clf, n_estimators=\"auto\", verbose=2, random_state=42)\n",
    "boruta_selector.fit(X_train, y_train)\n",
    "# 5. 获取被选中的重要特征\n",
    "selected_features = X.columns[boruta_selector.support_]\n",
    "print(f\"⭐ 选中的重要特征: {selected_features.tolist()}\")\n",
    "\n",
    "# 6. 获取被 Boruta 拒绝的特征\n",
    "rejected_features = X.columns[boruta_selector.support_ == False]\n",
    "#print(f\"🚫 被拒绝的特征: {rejected_features.tolist()}\")\n",
    "\n",
    "# 7. 绘制特征重要性对比\n",
    "feature_ranks = boruta_selector.ranking_\n",
    "sorted_idx = np.argsort(feature_ranks)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.xticks(rotation=90)\n",
    "plt.barh(X.columns[sorted_idx], feature_ranks[sorted_idx], color=\"royalblue\")\n",
    "plt.xlabel(\"Boruta Feature Ranking (Lower is Better)\", fontsize=12)\n",
    "plt.ylabel(\"Feature\", fontsize=12)\n",
    "plt.title(\"Boruta Feature Selection\", fontsize=14)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ],
   "id": "b9c7f23739c8d8ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "svm = SVC(kernel=\"linear\", C=1)\n",
    "feature_names =X.columns\n",
    "\n",
    "# 2️⃣ 进行 RFE 递归特征消除,SVM对尺度敏感\n",
    "rfe = RFE(estimator=svm, n_features_to_select=1)  # 选到只剩 1 个特征\n",
    "rfe.fit(X_scaled, y_train)\n",
    "\n",
    "X_test_selected = rfe.transform(X_test)\n",
    "# 3️⃣ 获取特征排名\n",
    "feature_ranking = rfe.ranking_  # 排名，数值越小，代表越重要\n",
    "sorted_idx = np.argsort(feature_ranking)  # 按排名升序排序\n",
    "sorted_features = np.array(feature_names)[sorted_idx]\n",
    "\n",
    "# 4️⃣ 画出特征重要性\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.barh(sorted_features, feature_ranking[sorted_idx], color=\"blue\", alpha=0.7)\n",
    "plt.xlabel(\"Feature Importance Rank (Lower is More Important)\",fontsize=10)\n",
    "plt.ylabel(\"Features\",fontsize=10)\n",
    "plt.title(\"Feature Importance Ranking using SVM-RFE\")\n",
    "plt.gca().invert_yaxis()  # 让最重要的特征在最上方\n",
    "plt.show()"
   ],
   "id": "7a50c292f82fbd28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#相对特征再来进行训练",
   "id": "fd4ce808a1aac431",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "id": "651bd75ba3da4d7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4eb2697ebc909e8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "id": "81255455614e5b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# #单独分析比赛 68819\n",
    "# games = [64485,64765,68819]\n",
    "# max_cols = 2 #每行最多显示2张\n",
    "# num_plots = 2 * len(games)\n",
    "# rows = (num_plots + max_cols - 1) // max_cols\n",
    "# cols = min(max_cols, num_plots)\n",
    "# plt.figure(figsize=(15, rows * 3))\n",
    "# for j in range(len(games)):\n",
    "#     gameid  = games[j]\n",
    "#     game_df = data[data['gameid'] == gameid]\n",
    "#     teams = game_df['teamid'].unique()\n",
    "#     for i in range(len(teams)):\n",
    "#         teamid = teams[i]\n",
    "#         team_df = game_df[game_df['teamid'] == teamid]\n",
    "#         res_df = pd.DataFrame()\n",
    "#         for event in index_definition.STRENGTH_EVENTS:\n",
    "#             condition = team_df.eval(event)\n",
    "#             condition_df = team_df[condition]\n",
    "#             res_df = condition_df if res_df.empty else pd.concat([res_df, condition_df],axis=0)\n",
    "#         ax = plt.subplot(rows, cols, i + 2*j + 1)\n",
    "#         plt.subplots_adjust(hspace=1)  # 值在 0 到 1 之间，值越大行间距越大\n",
    "#        # value_counts = res_df['eventname'].value_counts()\n",
    "#        # sns.countplot(x='eventname', data=res_df, order=value_counts.index, palette=\"viridis\",ax=ax)\n",
    "#         value_counts = team_df['eventname'].value_counts()\n",
    "#         sns.countplot(x='eventname', data=team_df, order=value_counts.index, palette=\"viridis\",ax=ax)\n",
    "# \n",
    "#         # plt.xticks(rotation=70)\n",
    "#         plt.title('Game {}: Team {}'.format(gameid,teamid))\n",
    "# \n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "4d762aab205e7eb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# games = [64485, 64765,68819,87906]\n",
    "# max_cols = 2  #每行最多显示2张\n",
    "# num_plots = 2 * len(games)\n",
    "# rows = (num_plots + max_cols - 1) // max_cols\n",
    "# cols = min(max_cols, num_plots)\n",
    "# plt.figure(figsize=(15, rows * 3))\n",
    "# for j in range(len(games)):\n",
    "#     gameid = games[j]\n",
    "#     home_control_rate, visit_control_rate, home_max_control_time, visit_max_control_time = common.get_control_rate0(data, gameid)\n",
    "#     print(\"主队平均控球时间：\" + str(sum(home_max_control_time) / len(home_max_control_time)))\n",
    "#     print(\"客队平均控球时间：\" + str(sum(visit_max_control_time) / len(visit_max_control_time)))\n",
    "# \n",
    "#     # plt.scatter( x=range(len(home_max_control_time)),y=list(home_max_control_time),marker='o',label='Home Team')\n",
    "#     # plt.scatter(x=range(len(visit_max_control_time)),y=list(visit_max_control_time),marker='x',label='Visit Team')\n",
    "#     ax = plt.subplot(rows, cols, j + 1)\n",
    "#     sns.lineplot(x=range(len(home_max_control_time)), y=list(home_max_control_time), color='r', label='Home Team',\n",
    "#                  ax=ax)\n",
    "#     sns.lineplot(x=range(len(visit_max_control_time)), y=list(visit_max_control_time), color='b', label='Visit Team',\n",
    "#                  ax=ax)\n",
    "#     plt.legend()\n",
    "#     plt.title('Game {}'.format(gameid))\n",
    "# plt.show()\n"
   ],
   "id": "d5dc96567f0570c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "31e940c3c63f747b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
